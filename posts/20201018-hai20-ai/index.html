<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.79.0" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>HAI 2020 AI&nbsp;&ndash;&nbsp;Brian Tang&#39;s Zettelkasten</title><link rel="stylesheet" href="/css/core.min.fdd0c10c69278cc03d9be012aebfa3d67fab991836ab33c143c5c8c08ae542333a23b967a5169ad4fb896277685f2e13.css" integrity="sha384-/dDBDGknjMA9m&#43;ASrr&#43;j1n&#43;rmRg2qzPBQ8XIwIrlQjM6I7lnpRaa1PuJYndoXy4T"><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="HAI 2020 AI" /><body><section id="header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><span class="site name">Brian Tang's Zettelkasten</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/categories/">Categories</a><a class="nav item" href="/tags/">Tags</a><a class="nav item" href="/about">About</a><a class="nav item" href="/charts">Charts</a></nav></div></span></div></section><section id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">HAI 2020 AI</h1><p class="article date">Sunday, October 18, 2020</p></section><article class="article markdown-body"><p>HAI 20 notes on knowledge graphs.</p>
<h2 id="yejin-chois-work">Yejin Choi's work</h2>
<p>Kahneman's 3 cognitive systems:</p>
<ul>
<li>Perception (object recognition, image segmentation)</li>
<li>Intuition (intuitive inferences on pre/post-conditions, motivations and intents, mental emotional states, what happens before and after?)</li>
<li>Reasoning (problem solving)</li>
</ul>
<p>We hallucinate and imagine stories based on our intuition. These may not be true all the time, these are very stochastic and needs context.</p>
<p>Relationship graph of objects and context. Even a caption isn't enough, (why is this occurring, what happened before, what happens after)</p>
<p>You can make inferences on images, videos, audio, and text about the context by asking questions.</p>
<p>Since we need the whole language model, reasoning becomes a generative task (asking questions), rather than a discriminative task because the space of reasoning in language is infinite.</p>
<p>MTurk to crowdsource common knowledge around event prompts with natural lanugage.</p>
<p>ATOMIC: An atlas of machine commonsense for if-then reasoning
COMeT: Yejin Choi
Social chemistry 101: Learning to reason about social and moral norms</p>
<p>Can try to direct the inferences made by COMET or ATOMIC towards privacy related speculations and reasonings.</p>
<p>Reasons are used to justify oneself and convince others. Intuitive inferences typically guide oneself.</p>
<p>Transformer based seq2seq models</p>
<h2 id="more-general-discussion">More general discussion</h2>
<p>Privacy is fundamental concept that we can abstract just like time, physics, objects, actions, locations&hellip; Can we figure out some smarter way to approach this other than the current paradigm of supervised and unsupervised learning?</p>
<p>Maybe there exists some meta learning algorithm which can figure out which model architecture to use for certain scenarios, which dataset, which learning rule, which task&hellip;</p>
<p>Latent variable model with some prior and arrows going to the data. Classic probabilistic language models can be framed in this way. Self-supervised learning like BERT or GPT uses very little assumed structure (a generative model). Generative models are obviously going to generate very realistic things since that was how they were structured to approach their task. Reasoning is difficult as it imagines things we have never seen before and are very different from our experience. Imagine self-supervised learning with some sort of common sense prior.</p>
<p>Stronger the language model is, the faster the generalization is.</p>
<p>Analogy and common sense</p>
<p>Common sense is something we all know before we even know language. Multiple stages of knowledge like from adolescence.</p>
<p>How can we imagine what it's like to crash in a car or drown in water without having experienced it?</p>
<p>Intuition and this system 1, system 2 thinking does not actually exist. Learning is very complex. There can be vague intuition or strong intuition, right or wrong, etc&hellip;</p>
<p>Conscious vs unconscious reasoning. Emotion based or moral judgements. Intuition could just be fast, unconscious, but can have a lot of computational structure.</p>
<p>There is no real way to assign actual probabilistic scoring, we are inconsistent in scoring? Sometimes we subconsciously or unconsciously understand problems or concepts.</p>
<h2 id="links">Links</h2>
<ul>
<li><a href="http://byron123t.github.io/posts/20201015-meta-learning/">HAI 20 Meta</a></li>
<li><a href="http://byron123t.github.io/posts/20201015-hri-learning/">HAI 20 HRI</a></li>
</ul></article><section class="article labels"><a class="category" href=/categories/research/>research</a><a class="tag" href=/tags/neuroscience/>neuroscience</a><a class="tag" href=/tags/psychology/>psychology</a><a class="tag" href=/tags/machinelearning/>machinelearning</a><a class="tag" href=/tags/nlp/>nlp</a></section>
</div>
<div class="article bottom"><section class="article navigation"><p><a class="link" href="/posts/20201018-hri-privacy/"><span class="iconfont icon-article"></span>HRI Privacy</a></p><p><a class="link" href="/posts/20201017-hri-privacy/"><span class="iconfont icon-article"></span>HRI Privacy</a></p></section></div></section><section id="footer"><div class="footer-wrap">
    <p class="copyright">Â©2019 Notepadium.</p>
    <p class="powerby"><span>Powered&nbsp;by&nbsp;</span><a href="https://gohugo.io" 
        target="_blank">Hugo</a><span>&nbsp;&amp;&nbsp;</span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank">Notepadium</a></p></div></section></body>

</html>